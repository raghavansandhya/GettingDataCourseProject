<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>Project Description</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>Project Description</h2>

<p>One of the most exciting areas in all of data science right now is wearable computing.ompanies like Fitbit, Nike, and Jawbone Up are racing to develop the most advanced algorithms to attract new users. The data linked to from the course website represent data collected from the accelerometers from the Samsung Galaxy S smartphone. A full description is available at the site where the data was obtained</p>

<p><a href="http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones">http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones</a></p>

<p>The dataset used for the project is below:</p>

<p><a href="https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip">https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip</a></p>

<h2>Source Dataset Description</h2>

<p>The source dataset contains results of experiments carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist.Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.</p>

<h2>Analysis of Source Dataset</h2>

<p>There are a total of 7352 obs. in Training Dataset and 2947 obs. in Test Dataset.</p>

<p>From the source dataset the following files were used for Analysis, Cleansing and Creation of Tidy dataset for Average of Activity Measurement.</p>

<ol>
<li><p><strong>features.txt</strong> - Contains list of all(561) measurment Variables in the Training and Test Dataset Files</p></li>
<li><p><strong>features_info.txt</strong> - Contains information about the different kind of measurements taken.</p></li>
<li><p><strong>activity_labels.txt</strong> - Conains the activity id and its corresponding activity labels for the different kind of activities performed by the subject.</p></li>
<li><p><strong>[test|train]/X_[test|rain].txt</strong> - Contains the Training Dataset measurement information for the 561 different features.</p></li>
<li><p><strong>[test|train]/y_[test|train].txt</strong> - Contains the activity_id information for each observation made.</p></li>
<li><p><strong>[test|train]/subject_[test|train].txt</strong> - Contains the participating subject_id information for each observation made.</p></li>
</ol>

<h2>Creation Tidy dataset for Average of Mean and STD of Activity Measurement</h2>

<p>Steps performed:</p>

<ol>
<li><p>Combined the subject<em>[test|train].txt, X</em>[test|rain].txt and y_[test|rain].txt files <strong>column-wise</strong> for each of the test and training datasets. This created a combined_test and combined_training data with 563 columns in each.</p></li>
<li><p>Merged the combined_test and combined_training data <strong>row-wise</strong> to create the complete dataset. The complete dataset now has 10299 obs and 563 columns</p></li>
<li><p>Extracted the mean and standard deviation variables of each measurement and created an intermediate dataset by performing a keyword search for the keywords &ldquo;mean&rdquo; and &ldquo;std&rdquo; in the column names of the complete dataset. Skipped the angle measurement based mean and std variables as they are more of sub measurements. We would now have only 79 distinct variables</p></li>
<li><p>Joined the intermediate dataset with the activity_labels.txt on activity_id data to get the descriptive activity names for each observation and replaced the activity_id with the same. </p></li>
<li><p>The column names for variables in the intermediate file are not very descriptive of the kind of measurment and do not comply very much to the column naming standards of a tidy dataset. So renamed the columns with a more descriptive name as per the information provided in the features_info.txt.</p></li>
<li><p>Finally, created the tidy dataset by giving the average of each column in the intermediate file which yeilds the dataset for &#39;Average of Mean and Standard Deviation of Activity Measurement&#39; for each activity and subject. Since there are 30 subjects and 6 different activities this final dataset has (30 X 6) 180 records with 81 columns including the subject_id and activity.</p></li>
</ol>

<p>##R Code wriiten for analysis</p>

<p>The R program written for this analysis is [run_analysis.R].</p>

<p>##Tidy Dataset</p>

<p>The <strong>Average_of_Mean_and_STD_of_Activity_Measurment.txt</strong> contains total of 180 records for 30 subjects (identified by subject_id) across 6 differnet Activities</p>

</body>

</html>
